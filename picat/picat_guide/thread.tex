\ignore{
\documentstyle[11pt]{report}
\textwidth 13.7cm
\textheight 21.5cm
\newcommand{\myimp}{\verb+ :- +}
\newcommand{\ignore}[1]{}
\def\definitionname{Definition}

\makeindex
\begin{document}
}

\chapter{\label{chapter:thread}Threads}
%\pagenumbering{arabic}

With event-driven actors\index{action rule}, a program's execution in Picat is no longer single-threaded\index{thread}. When an event occurs, the predicate or function that is currently being executed will be interrupted, and control will be moved to the actors\index{action rule} that are activated. Actors\index{action rule} run concurrently, but do not run in parallel. This means that, at any time, only one actor\index{action rule} can run. An actor's\index{action rule} execution can be interrupted by another event, causing a different actor\index{action rule} to run. After all of the activated actors\index{action rule} finish their execution, the predicate or function that was interrupted will resume its execution. 

With the availability of multi-core processors, parallel processing has gained new prominence in delivering high-performance computing. The emergence of multi-core processors has the potential for breaking the performance barrier, especially for combinatorial optimization problems, which demand ever-increasing computational power. Picat's \texttt{thread} module can be used to program concurrent and parallel tasks as threads\index{thread}. A \emph{thread}\index{thread} is represented as an attributed variable\index{attributed variable} that contains, among other attributes\index{attributed variable}, a thread\index{thread} descriptor. A thread\index{thread} can serve as a communication channel to which actors\index{action rule} can be attached, and through which messages can be sent to actors\index{action rule} running in the same or in different threads\index{thread}.

Each thread\index{thread} runs on a separate Picat virtual machine that has its own stack and heap. All threads\index{thread} share the following areas: symbol tables, the code area, the file and socket table, the table area, and the global map\index{global map}. At the implementation level, Picat synchronizes the operations of these areas in order to ensure consistency of data.

\section{Starting and Terminating Threads}
Let's begin with an example.

\subsection*{Example}
\begin{verbatim}
import thread.

main =>
    PingThread = new_thread(ping_pong,ping,10),
    PongThread = new_thread(ping_pong,pong,10),
    PingThread.start(),
    PongThread.start().

ping_pong(Msg,N) =>
    foreach(I in 1..N)
        writeln(Msg)
    end.
\end{verbatim}
The \texttt{main} predicate creates two threads\index{thread}: \texttt{PingThread} and \texttt{PongThread}. After starting, \texttt{PingThread} executes the call \texttt{ping\_pong(ping,10)} to display \texttt{ping} 10 times, and \\ \texttt{PongThread} executes the call \texttt{ping\_pong(pong,10)} to display \texttt{pong} 10 times. The main thread\index{thread} will wait until both \texttt{PingThread} and \texttt{PongThread} terminate. In the standard output, users will see the lines in a random order.

This example uses the following built-ins. 
\begin{itemize}
\item \texttt{new\_thread($S$, $Arg_1$, $\ldots$, $Arg_n$) = $Thread$}\index{\texttt{new\_thread}}: This function creates a new thread\index{thread}, which will execute the call 
\begin{tabbing}
aa \= aaa \= aaa \= aaa \= aaa \= aaa \= aaa \kill
\> \texttt{call($S$,$Arg_1$,$\ldots$,$Arg_n$)}\index{\texttt{call}}. 
\end{tabbing}
The return value of the function \texttt{new\_thread}\index{\texttt{new\_thread}} is an attributed variable\index{attributed variable} that contains, among other attributes\index{attributed variable}, an attribute\index{attributed variable} named \texttt{thread\_id}. 
\item \texttt{start($Thread$)}\index{\texttt{start/1}}: This predicate puts $Thread$ into the \emph{ready} state, allowing the scheduler to schedule it for execution.
\end{itemize}

A thread\index{thread} terminates in the following situations: (1) when it executes the predicate \texttt{halt}\index{\texttt{halt/0}}; (2) when the call that it executes succeeds, and all of the sub-threads\index{thread} that are created by the call have terminated; (3) when the call that it executes fails. When a thread\index{thread} terminates, all of its sub-threads\index{thread} will also terminate.

In this example, the \texttt{EchoThread} installs an actor\index{action rule}, and then loops until \texttt{Flag} becomes a non-variable.  The \texttt{SenderThread} sends \texttt{hello} to \texttt{EchoThread} three times, and then sends \texttt{done} to \texttt{EchoThread}, causing it to kill itself. After sending the messages, the \texttt{SenderThread} terminates.

\section{Making Threads Wait}
Consider the following code.

\subsection*{Example}
\begin{verbatim}
import thread.

main =>
    Thread1 = new_thread(make_key),
    Thread1.start(),
    println(get_global_map().get(thread_key)).

make_key =>
    get_global_map().put(thread_key, 1).
\end{verbatim}

This code creates a new thread\index{thread}, which puts a key-value pair in the global map\index{global map}, which is shared by all threads\index{thread}.  The main thread\index{thread} is supposed to print the value that the other thread\index{thread}, \texttt{Thread1}, stores in the global map\index{global map}.  However, the main thread\index{thread} and \texttt{Thread1} are executing in parallel, so there is no guarantee that \texttt{Thread1} will have stored \texttt{thread\_key} on the global map\index{global map} by the time that the main thread\index{thread} tries to retrieve the key's value.  If the main thread\index{thread} calls \texttt{println}\index{\texttt{println/1}} before \texttt{Thread1} stores \texttt{thread\_key} on the global map\index{global map}, then the program will raise the exception \texttt{key\_not\_found(thread\_key, main)}.

The solution to this problem is to have the \texttt{main} thread\index{thread} wait for \texttt{Thread1} to finish execution.  This is accomplished by using the \texttt{join}\index{\texttt{join/1}} predicate, as in the following code.

\subsection*{Example}
\begin{verbatim}
import thread.

main =>
    Thread1 = new_thread(make_key),
    Thread1.start(),
    join(Thread1),
    println(get_global_map().get(thread_key)).

make_key =>
    get_global_map().put(thread_key, 1).
\end{verbatim}

The line \texttt{join(Thread1)}\index{\texttt{join/1}} causes the \texttt{main} thread\index{thread} to wait for \texttt{Thread1} to finish execution.  Then, assuming that no error has occurred, \texttt{thread\_key} will be stored on the global map\index{global map} before the \texttt{main} thread\index{thread} tries to access it.

The \texttt{thread} module has two predicates that cause a thread\index{thread} to wait.

\begin{itemize}
\item \texttt{join($Thread$)}\index{\texttt{join/1}}: This predicate causes the current thread\index{thread} to wait until $Thread$ finishes running.  This means that the current thread\index{thread} does not execute any more code until $Thread$ terminates.
\item \texttt{sleep($Milliseconds$)}\index{\texttt{sleep/1}}: This predicate causes the current thread\index{thread} to pause execution until $Milliseconds$ time has passed.
\end{itemize}

\subsection{Deadlock}
The \texttt{thread} module has a \texttt{this\_thread()}\index{\texttt{this\_thread/0}} function, which returns the thread\index{thread} that calls the function.

\begin{itemize}
\item \texttt{this\_thread() = $Thread$}\index{\texttt{this\_thread/0}}: The built-in function \texttt{this\_thread()}\index{\texttt{this\_thread/0}} returns the executing thread\index{thread} of the function call. 
\end{itemize}

Suppose that a thread\index{thread} calls \texttt{join(this\_thread())}\index{\texttt{join/1}}\index{\texttt{this\_thread/0}}.  This causes a thread\index{thread} to wait for itself before the thread\index{thread} continues to run.  This code is the simplest example of a \emph{deadlock}\index{deadlock}.  Deadlocks\index{deadlock} occur when at least one thread\index{thread} is waiting forever, consuming resources.

\section {Mutual Exclusion}
\emph{Mutual exclusion} occurs when multiple threads\index{thread} need to access a shared resource, but only one thread\index{thread} can access the resource at any given time.

Consider the following code.

\subsection*{Example}
\begin{verbatim}
import thread, io.

main =>
    FD = io.open("threads.txt", write),
    Thread1 = new_thread(print_val, 1, FD),
    Thread2 = new_thread(print_val, 2, FD),
    Thread1.start(),
    Thread2.start(),
    join(Thread1),
    join(Thread2),
    io.close(FD).

print_val(I, FD) =>
    io.fprintf(FD, "Thread %d is writing %d.", I, I).
\end{verbatim}

In this code, both \texttt{Thread1} and \texttt{Thread2} are accessing \texttt{threads.txt}.  It is possible for both threads\index{thread} to write to the file at the same time, causing their output to interleave.  For example, after the above code executes, the contents of \texttt{threads.txt} can be:

\begin{verbatim}
Thread 1 is wriThread2 isting writing 2
1
\end{verbatim}

This occurs because both threads\index{thread} are simultaneously trying to access a shared resource, \\ \texttt{threads.txt}.  In order to solve this problem, and to allow mutual exclusion, access to shared resources, such as variables and files, should be placed in a \emph{critical section}\index{critical section} of code, which can only be accessed by one thread\index{thread} at a time.  The \texttt{thread} module has four ways to provide mutual exclusion: using a \emph{mutex}\index{mutex}, using a \emph{semaphore}\index{semaphore}, using a \emph{read-write lock}\index{read-write lock}, and using a \emph{condition variable}\index{condition variable}.

\subsection{Mutex Locks}
A \emph{mutex}\index{mutex} is a structure that has two possible states: \emph{locked} and \emph{unlocked}.  When a thread\index{thread} wants to access a critical section\index{critical section} of code, it tries to acquire the mutex\index{mutex}.  If the mutex\index{mutex} is unlocked, then the thread\index{thread} acquires the mutex\index{mutex} immediately, and locks the mutex\index{mutex}; after the thread\index{thread} leaves the critical section\index{critical section}, it unlocks the mutex\index{mutex}.  Otherwise, if the mutex\index{mutex} is locked, then that means that another thread\index{thread} has locked the mutex\index{mutex}, and is executing the critical section\index{critical section}; in this case, the thread\index{thread} that is currently trying to acquire the mutex\index{mutex} will block until the mutex\index{mutex} is unlocked.

Picat has three built-ins that manage mutex\index{mutex} locks.

\begin{itemize}
\item \texttt{new\_mutex() = $Mutex$}\index{\texttt{new\_mutex/0}}: This function creates a new mutex\index{mutex} lock.
\item \texttt{acquire\_mutex($Mutex$)}\index{\texttt{acquire\_mutex/1}}: This predicate is used to acquire a mutex\index{mutex} lock.  If the mutex\index{mutex} is currently in the \texttt{unlocked} state, then the current thread\index{thread} acquires the mutex\index{mutex} and locks it.  Otherwise, if the mutex\index{mutex} is in the \texttt{locked} state, then the current thread\index{thread} waits until the mutex\index{mutex} is unlocked, after which the thread\index{thread} tries again to acquire the mutex\index{mutex}.
\item \texttt{release\_mutex($Mutex$)}\index{\texttt{release\_mutex/1}}: This predicate is used to release a mutex\index{mutex} lock.  It unlocks the mutex\index{mutex}, allowing waiting threads\index{thread}, which are trying to acquire the mutex\index{mutex}, to continue running.  Note that a mutex\index{mutex} can only be released by the thread\index{thread} that has acquired the mutex\index{mutex}.
\end{itemize}

For example, the following code modifies the \texttt{print\_val} example to use a mutex\index{mutex} lock.

\subsection*{Example}
\begin{verbatim}
import thread, io.

main =>
    FD = io.open("threads.txt", write),
    Mutex = new_mutex(),
    Thread1 = new_thread(print_val, Mutex, 1, FD),
    Thread2 = new_thread(print_val, Mutex, 2, FD),
    Thread1.start(),
    Thread2.start(),
    join(Thread1),
    join(Thread2),
    io.close(FD).

print_val(Lock, I, FD) =>
   acquire_mutex(Lock), % Enter critical section
   output_val(I, FD),
   release_mutex(Lock). % Leave critical section

output_val(I, FD) =>  % Critical Section
    io.fprintf(FD, "Thread %d is writing %d.", I, I). 
\end{verbatim}

This code locks the mutex\index{mutex} before writing to \texttt{threads.txt}, meaning that the output of the threads\index{thread} will not interleave.

\subsubsection{Deadlock}
It is possible for mutex\index{mutex} locks to cause deadlocks\index{deadlock}, in which two or more threads\index{thread} are waiting for each other to release mutex\index{mutex} locks.

\subsection*{Example}
\begin{verbatim}
import thread.

main =>
    Mutex1 = new_mutex(),
    Mutex2 = new_mutex(),
    Thread1 = new_thread(go, Mutex1, Mutex2),
    Thread2 = new_thread(go, Mutex2, Mutex1),
    Thread1.start(),
    Thread2.start(),

go(First_Lock, Second_Lock) =>
    acquire_mutex(First_Lock),
    acquire_mutex(Second_Lock),
    critical_code(), % user-defined critical section
    release_mutex(Second_Lock),
    release_mutex(First_Lock).
\end{verbatim}

In this example, it is possible for \texttt{Thread1} to acquire \texttt{Mutex1} while \texttt{Thread2} acquires \texttt{Mutex2}.  Then, \texttt{Thread1} waits forever for \texttt{Thread2} to release \texttt{Mutex2}, while \texttt{Thread2} waits forever for \texttt{Thread1} to release \texttt{Mutex1}.  This causes a deadlock\index{deadlock}.  One way to avoid this problem is to ensure that all threads\index{thread} acquire locks in the same order.  For example, if both \texttt{Thread1} and \texttt{Thread2} would try to acquire \texttt{Mutex1} before \texttt{Mutex2}, then the thread\index{thread} that acquires \texttt{Mutex1} can also acquire \texttt{Mutex2}, and can continue running while the other thread\index{thread} waits.

\subsubsection{Starvation}
Another problem that can occur with mutex\index{mutex} locks is \emph{starvation}\index{starvation}, where a thread\index{thread} can wait forever to access a critical section\index{critical section}.  For example, consider the following code fragment.

\begin{verbatim}
while (true)
    acquire_mutex(Mutex),
    critical_code(), % user-defined critical section
    release_mutex(Mutex)
end.
\end{verbatim}

If multiple threads\index{thread} are executing this while loop, then it is possible for the system to give these threads\index{thread} different priorities.  It is possible for a low-priority thread\index{thread} to wait forever to acquire \texttt{Mutex}, while threads\index{thread} with higher priorities repeatedly acquire and release the mutex\index{mutex}.

\subsection{Semaphores}
A \emph{semaphore}\index{semaphore} is a structure that contains an integer.  Unlike mutex\index{mutex} locks, which only have two states, the semaphore's\index{semaphore} integer can any value between $0$ and the maximum integer to which the semaphore\index{semaphore} is initialized.  When a thread\index{thread} wants to access a critical section\index{critical section} of code, it tries to access the semaphore\index{semaphore} by decreasing the semaphore's\index{semaphore} integer value.  If the integer value is greater than $0$, then the value is decreased by one, and the thread\index{thread} can access the critical section\index{critical section}.  Otherwise, the integer value is currently $0$, and the thread\index{thread} must wait for the integer value to increase; then, the thread\index{thread} again tries to decrease the semaphore's\index{semaphore} integer value and continue.

Picat has four built-ins that manage semaphores\index{semaphore}.

\begin{itemize}
\item \texttt{new\_semaphore() = $Semaphore$}\index{\texttt{new\_semaphore/0}}: This function creates a new semaphore\index{semaphore}, with an initial integer value of $1$.
\item \texttt{new\_semaphore($N$) = $Semaphore$}\index{\texttt{new\_semaphore/1}}: This function creates a new semaphore\index{semaphore}, with an initial integer value of $N$.
\item \texttt{p\_semaphore($Semaphore$)}\index{\texttt{p\_semaphore/1}}: This predicate tries to decrease the semaphore's\index{semaphore} integer value.  If the value is currently non-zero, then this predicate decreases the value by one, and the current thread\index{thread} continues.  Otherwise, the value is zero, and the current thread\index{thread} waits until the value is increased, and then tries again to decrease the semaphore's\index{semaphore} integer value.
\item \texttt{v\_semaphore($Semaphore$)}\index{\texttt{v\_semaphore/1}}: This predicate increases the semaphore's\index{semaphore} integer value by one.  If the value was zero, then threads\index{thread} that have blocked while calling \texttt{p\_semaphore}\index{\texttt{p\_semaphore/1}} will try again to decrease the semaphore's\index{semaphore} integer value.
\end{itemize}

For example, the following code modifies the \texttt{print\_val} example to use a semaphore\index{semaphore}.

\subsection*{Example}
\begin{verbatim}
import thread, io.

main =>
    FD = io.open("threads.txt", write),
    Semaphore = new_semaphore(),
    Thread1 = new_thread(print_val, Semaphore, 1, FD),
    Thread2 = new_thread(print_val, Semaphore, 2, FD),
    Thread1.start(),
    Thread2.start(),
    join(Thread1),
    join(Thread2),
    io.close(FD).

print_val(Semaphore, I, FD) =>
   p_semaphore(Semaphore), % Enter critical section
   output_val(I, FD),
   v_semaphore(Semaphore). % Leave critical section

output_val(I, FD) =>   % Critical Section
    io.fprintf(FD, "Thread %d is writing %d.", I, I).
\end{verbatim}

\subsubsection{Differences Between Mutex Locks and Semaphores}
A mutex\index{mutex} lock has two states: \texttt{locked} and \texttt{unlocked}.  This means that only one thread\index{thread} can access the shared code at any time.  A semaphore\index{semaphore} can take multiple values.  If a semaphore\index{semaphore} is initialized with \texttt{new\_semaphore($N$)}\index{\texttt{new\_semaphore/1}}, then up to $N$ threads\index{thread} can access the shared code at any time.

Mutex\index{mutex} locks can cause starvation\index{starvation}, because a mutex\index{mutex} can only be unlocked by the thread\index{thread} that locked it.  Semaphores\index{semaphore} decrease the problem of starvation\index{starvation}, because multiple threads\index{thread} can call \texttt{v\_semaphore}\index{\texttt{v\_semaphore/1}}, allowing a low-priority thread\index{thread} to have a greater possibility of entering a shared section of code.

\section{Read-Write Locks}
Sometimes, when multiple threads\index{thread} need to access a file, using a mutex\index{mutex} lock can have a large amount of overhead.  For example, when multiple threads\index{thread} need to read from a file, if each thread\index{thread} uses a mutex\index{mutex} before reading, then the other threads\index{thread} will need to wait, even though the file is not being modified.  

This problem is solved by using a \emph{read-write lock}\index{read-write lock}.  A read-write lock\index{read-write lock} is a structure that has three possible states: \emph{read\_locked}, \emph{write\_locked}, and \emph{unlocked}.  Read-write locks\index{read-write lock} allow multiple readers to acquire the lock at the same time, unless a writer has acquired the lock.  In other words, at any given time, if the lock is locked, then either a single writer has acquired the lock, or one or more readers have acquired the lock.  This means that readers only need to wait when another thread\index{thread} is writing.

Picat has four built-ins that manage read-write locks\index{read-write lock}.

\begin{itemize}
\item \texttt{new\_rwlock() = $RWLock$}\index{\texttt{new\_rwlock/0}}: This function creates a new read-write lock\index{read-write lock}.
\item \texttt{rdlock($RWLock$)}\index{\texttt{rdlock/1}}: This predicate is used to acquire a read-write lock\index{read-write lock} for reading.  If the read-write lock\index{read-write lock} is currently in the \texttt{unlocked} or the \texttt{read\_locked} state, then the current thread\index{thread} acquires the read-write lock\index{read-write lock}, and locks it for reading.  Otherwise, if the read-write lock\index{read-write lock} is in the \texttt{write\_locked} state, then the current thread\index{thread} waits until the read-write lock\index{read-write lock} is either unlocked, or locked for reading, after which the thread\index{thread} tries again to acquire the read-write lock\index{read-write lock}.
\item \texttt{wrlock($RWLock$)}\index{\texttt{wrlock/1}}: This predicate is used to acquire a read-write lock\index{read-write lock} for writing.  If the read-write lock\index{read-write lock} is currently in the \texttt{unlocked} state, then the current thread\index{thread} acquires the read-write lock\index{read-write lock}, and locks it for writing.  Otherwise, if the read-write lock\index{read-write lock} is in the \texttt{read\_locked} or the \texttt{write\_locked} state, then the current thread\index{thread} waits until the read-write lock\index{read-write lock} is unlocked, after which the thread\index{thread} tries again to acquire the read-write lock\index{read-write lock}.
\item \texttt{rwunlock($RWLock$)}\index{\texttt{rwunlock/1}}: This predicate is used to release a read-write lock\index{read-write lock}.  It unlocks the read-write lock\index{read-write lock}.  If no other threads\index{thread} have acquired the read-write lock\index{read-write lock} for reading, then, waiting threads\index{thread}, which are trying to acquire the read-write lock\index{read-write lock}, can continue running.
\end{itemize}

The following code shows how to use a read-write lock\index{read-write lock} to manage two threads\index{thread} that are reading from a file, and one thread\index{thread} that is writing to a file.

\subsection*{Example}
\begin{verbatim}
import thread, io.

main =>
    FD = io.open("threads.txt", append),
    RWLock = new_rwlock(),
    Thread1 = new_thread(write_vals, RWLock, FD),
    Thread2 = new_thread(read_all, RWLock, FD),
    Thread3 = new_thread(read_all, RWLock, FD),
    Thread1.start(),
    Thread2.start(),
    Thread3.start(),
    join(Thread1),
    join(Thread2),
    join(Thread3),
    io.close(FD).

write_vals(RWLock, FD) =>
   wrlock(RWLock),   % Enter critical section
   foreach (I in 1 .. 1000000)
       io.fprintln(FD, I)
   end,
   wrunlock(RWLock). % Leave critical section

read_all(RWLock, FD) =>
    rdlock(RWLock),   % Enter critical section
    Str = io.fread_file_chars(FD),
    wrunlock(RWLock). % Leave critical section
\end{verbatim}

In this example, it is possible for \texttt{Thread2} and \texttt{Thread3} to acquire \texttt{RWLock} at the same time.  However, if \texttt{Thread1} has already aquired \texttt{RWLock}, then \texttt{Thread2} and \texttt{Thread3} must wait until the lock is unlocked.

\section{Condition Variables}
Consider the following code.

\subsection*{Example}
\begin{verbatim}
import thread.

main =>
    get_global_map().put(X, 0),
    Mutex = new_mutex(),
    Thread1 = new_thread(change_map, Mutex),
    Thread2 = new_thread(blastoff, Mutex),
    Thread1.start(),
    Thread2.start().

change_map(Mutex) =>
    X1 = 0,
    foreach (I in 1 .. 1000000)
       process_code(), % user-defined code
       acquire_mutex(Mutex),
       X1 := get_global_map().get(X) + 1,
       get_global_map().put(X, X1),
       release_mutex(Mutex) 
    end.
    
blastoff(Mutex) =>
    acquire_mutex(Mutex),
    X = get_global_map.get(X),
    release_mutex(Mutex),
    while (X != 1000000)
           acquire_mutex(Mutex),
           X := get_global_map.get(X),
           release_mutex(Mutex).
    end,
    println("Blastoff!").
\end{verbatim}

In this code, \texttt{Thread2} repeatedly tests the value of \texttt{X} in the global map\index{global map}, until \texttt{X} is set to $1000000$.  This is called \emph{busy waiting}\index{busy waiting}, and wastes CPU processing time.  Furthermore, if \texttt{Thread2} has a higher priority than \texttt{Thread1}, then \texttt{Thread1} can be starved\index{starvation}, meaning that \texttt{Thread1} might never acquire \texttt{Mutex}, and the value of \texttt{X} might never reach $1000000$.  It would be more efficient for \texttt{Thread2} to block until \texttt{X} is set to $10000000$ instead of repeatedly locking a mutex\index{mutex} and testing the global map\index{global map}.  

This problem is solved by using a \emph{condition variable}\index{condition variable}.  A condition variable\index{condition variable} is used together with a mutex\index{mutex}.  After a thread\index{thread} has acquired the mutex\index{mutex}, the thread\index{thread} tests a condition, and waits to be signaled by the condition variable\index{condition variable}.  The condition variable\index{condition variable} suspends the thread\index{thread}, and unlocks the mutex\index{mutex}.  When the condition variable\index{condition variable} signals the thread\index{thread}, the thread\index{thread} automatically reacquires the mutex\index{mutex}.  This decreases the amount of busy waiting\index{busy waiting}, and allows other threads\index{thread} to access shared resources until the condition is true.

Picat has four built-ins that manage condition variables\index{condition variable}.

\begin{itemize}
\item \texttt{new\_cv() = $CV$}\index{\texttt{new\_cv/0}}: This function creates a new condition variable\index{condition variable}.
\item \texttt{wait\_cv($CV$, $Mutex$)}\index{\texttt{wait\_cv/2}}: When a thread\index{thread} calls this predicate, the thread\index{thread} is suspended, and the mutex\index{mutex} is temporarily released, until the condition variable\index{condition variable} signals the thread\index{thread}.
\item \texttt{signal\_cv($CV$)}\index{\texttt{signal\_cv/1}}: After a thread\index{thread} modifies a value which is associated with a condition, the thread\index{thread} can call this predicate.  This predicate wakes at least one thread\index{thread} that is waiting for the condition variable\index{condition variable}.  The thread\index{thread} reacquires its mutex\index{mutex}, and tests the condition again.
\item \texttt{broadcast\_cv($CV$)}\index{\texttt{broadcast\_cv/1}}: After a thread\index{thread} modifies a value which is associated with a condition, the thread\index{thread} can call this predicate.  This predicate wakes all of the threads\index{thread} that are waiting for the condition variable\index{condition variable}.  Each thread\index{thread} reacquires its mutex\index{mutex}, and tests the condition again.  If more than one thread\index{thread} has released the same mutex\index{mutex}, then only one of the threads\index{thread} can continue execution, and the other threads\index{thread} continue blocking until they can reacquire the mutex\index{mutex}.
\end{itemize}

The following code shows how to modify the \texttt{blastoff} example in order to eliminate busy waiting\index{busy waiting}.

\subsection*{Example}
\begin{verbatim}
import thread.

main =>
    get_global_map().put(X, 0),
    Mutex = new_mutex(),
    CV = new_cv(),
    Thread1 = new_thread(change_map, Mutex, CV),
    Thread2 = new_thread(blastoff, Mutex, CV),
    Thread1.start(),
    Thread2.start().

change_map(Mutex, CV) =>
    X1 = 0,
    foreach (I in 1 .. 1000000)
       process_code(), % user-defined code
       acquire_mutex(Mutex),
       X1 := get_global_map().get(X) + 1,
       get_global_map().put(X, X1),
       release_mutex(Mutex) 
    end,
    signal_cv(CV).
    
blastoff(Mutex, CV) =>
    acquire_mutex(Mutex),
    X = get_global_map.get(X),
    release_mutex(Mutex),
    while (X != 1000000)
           wait_cv(CV, Mutex),
           acquire_mutex(Mutex),
           X := get_global_map.get(X),
           release_mutex(Mutex).
    end,
    println("Blastoff!").
\end{verbatim}

In this code, the instruction \texttt{wait\_cv(CV, Mutex)}\index{\texttt{wait\_cv/2}} blocks \texttt{Thread2} until \texttt{Thread1} calls \texttt{signal\_cv(CV)}\index{\texttt{signal\_cv/1}}.  Then, even if \texttt{Thread2} has a higher priority, and has already acquired \texttt{Mutex}, the condition variable\index{condition variable} causes \texttt{Thread2} to release the mutex\index{mutex}, allowing \texttt{Thread1} to run.  

Note that \texttt{wait\_cv}\index{\texttt{wait\_cv/2}} should be called within the loop that tests the condition.  It is possible for a thread\index{thread} to be signaled when the condition has not yet been fulfilled.  Therefore, the thread\index{thread} must test the condition after the thread\index{thread} has been signaled.  If the condition has not been fulfilled, then the thread\index{thread} is blocked again, until the next time that the thread\index{thread} is signaled.

\ignore{
\end{document}
}